%!TEX ROOT=./fl_main.tex
\section{Background}
\label{sec:background}

 Most of the proposed approaches focus
on analysing the run-time behaviour during the model training. According to the
collected information and some predefined rules, these approaches decide whether
they can spot any abnormalities and report them~\cite{deeplocalize,
wardat2022deepdiagnosis, schoop2021umlaut}.

During the training of a DNN, \DL (DL)~\cite{deeplocalize} collects various performance indicators such as loss values, performance metrics, weights,
gradients and neuron activation values. The main idea behind this approach is that the historic trends in the performance evaluation or the values propagated between layers can serve as an indicator of a fault's presence. To allow the collection of the necessary data, a developer should insert a custom callback provided by the tool into the source code regulating the training process. A callback is a mechanism that is invoked at different stages of the model training (e.g. at the start or end of an epoch, before or after a single batch~\cite{keras}) to perform a set of desired actions - store historical data reflecting the dynamics of the training process in our case. Both tools then compare the analysed values with a list of pre-defined failure symptoms and root causes, which the authors have collected from the existing literature. Based on the performed analysis, \DL either claims that the model is \textit{correct} or outputs an error message listing the detected misbehaviours. The final output of \DL contains the (1) fault type, (2) the layer and the phase (feed forward or backward propagation) in which the DL program has a problem, and (3) the iteration in which  learning is stopped. The faults that the tool is able to detect include the following: "Error Before/After Activation", "Error in Loss Function", "Error Backward in Weight/$\Delta$ Weight", and "Model Doest not Learn" that suggests an incorrectly selected learning rate.

\DD (DD)~\cite{wardat2022deepdiagnosis} was built on the basis of \DL and improve the latter by enlarging the list of detected symptoms and connecting them to a set of actionable suggestions. It detects 10 types of faults: "Numerical Errors", "Exploding Tensor", "Unchanged Weight", "Saturated Activation", "Dead Node", "Activation Function's Output Out of Range", "Loss Not Decreasing", "Invalid Loss", "Invalid Accuracy", "Accuracy Not Increasing" and "Vanishing Gradient". Depending on the symptom, the actionable messages provided by Diagnosis suggest to change either the loss or optimisation function, layer number, initialisation of weights, learning rate, or indicate that training data is "improper". As \DL does not provide an output that can be translated into a specific fault affecting the model, we only use \DD in the empirical comparison of fault localisation tools.

Similarly to \DL and \DD, \UM (UM)~\cite{schoop2021umlaut} operates through a callback that is attached to the model training call. This tool
combines dynamic monitoring of the model behaviour during the training with
 heuristic static checks of the model structure and its parameters. As an output, it provides the results of the checks along with best practices and suggestions on how to deal with the detected faults. The tool comprises of 10 heuristics for which the authors found mentions in diverse set of sources such as API documentation and existing literature, lecture notes and textbooks, courses, blogs and non-scientific articles. The heuristics are divided by the area of application into "Data Preparation", "Model Architecture" and "Parameter Tuning". Data preparation heuristics are dynamic and check if the training data contains NaNs, has invalid shape, is not normalised or if the validation accuracy is higher than 95\% after the third epoch of the training. On the other hand, all model architecture heuristics are static and are focused on the usage of correct activation functions. Parameter tuning category combines both dynamic and static rules that aim to detect overfitting and control the values of the learning and dropout rates. As an output, the tool returns a list of heuristics that were violated.

%Unlike previously discussed methods, \NL~\cite{nikanjam2021automatic} is a model-based approach that employs meta-modelling and graph transformations for fault detection. Given a model under test, it constructs a meta-model consisting of the base skeleton and some fundamental properties. This model is then checked against a set of 23 rules embodied in graph transformations, each representing a fault or a design issue.

Nikanjam \etal~\cite{nikanjam2021automatic} propose \NL (NL), a model-based fault detection approach that uses meta-modelling and graph transformations. The technique starts with building a meta-model for DL programs that consists of their base structure and fundamental properties. It then performs a verification process that applies 23 pre-defined rules, implemented as graph transformations, to the meta-model, to check for any potential inefficiencies. The rules are classified into 4 high-level root causes as suggested by Zhang~\etal~\cite{Zhang:2018}:
"Incorrect Model Parameter or Structure" (5 rules), "Unaligned Tensor" (4 rules), "API Misuse" (5 rules), and "Structure Inefficiency" (9 rules). One example of "Unaligned Tensor" rule is a check whether consecutive layers in a model are compatible or whether the reshape of data did not lead to the loss of any elements. "API Misuse" includes a rule that ensures that optimiser is correctly defined and connected to the computational graph.
Another rule in this category inspects the parameters initialisation to detect the cases when initialisation is performed more than once or after the training has already started. The "Incorrect Model Parameter or Structure" rule controls that weights and biases are initialised with appropriate values and that suitable activation functions are used for specific layer types. "Structure Inefficiency" is responsible to detect flaws in the design and structure of DNN that can result in the drop of model performance. Among others, there are rules in this category that 
check if the number of neurons in fully connected layers is decreasing when moving from the input to the output layer or rules that check that pooling layers are not used after each applied convolution not to loose too much information about an input.

\dfd~\cite{deepfd} (DFD) is a learning-based framework that leverages mutation testing and popular ML algorithms to construct a tool capable of labelling a given DL program as correct or faulty according to a list of common fault types the tool has learned to detect. To train the classifiers that lie in the core of the technique, the authors prepare a set of correct and faulty models. Faulty models are obtained through the artificial injection of up to 5 mutations to each correct program used. The mutations that are used to inject faults are changing loss or optimisation function, changing learning rate, decreasing number of epochs, and changing activation functions. Consequently, these fault types correspond to the fault localisation capabilities of the tool. To construct the training dataset, all of the generated mutants and the original models are trained while run-time data of the same kind as for \DL, \DD, \UM are collected. The authors then extract 160 features from these data using statistical operations (e.g. calculating skewness, variance or standard deviation). As the next step, three popular ML algorithms (K-Nearest Neighbors~\cite{knearestn}, Decision Tree~\cite{breiman2017classification} and Random Forest~\cite{ho1995random}) are trained on the created dataset.  A union of the prediction results of these classifiers is used for fault identification and localisation in a given program under test. \dfd outputs a list of detected faults along with the code lines affected by each fault type.

The tools described in this section are built using a limited set of rules and best practices, fixed thresholds or training data, which creates an urge to explore the generalisability of these approaches to diverse programs and architectures.